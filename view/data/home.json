{
    "header":{
	"title":"home"
    },
    "body":[
	{
	    "heading":"About Me",
	    "content":"<p>My name is Atul Mirajkar. I have served as a software developer for two years (July 2011 - July 2013) in Geometric Limited. Currently I am pursuing Masters in Computer Science at University of Maryland Baltimore County. As part of my research I am currently exploring machine learning techniques to improve robot simulations using crowd sourced data.</p><p>Some of the problems being continuously tackled in IT industry and most of which I have encountered are related to that of computation of exponentially increasing data. Research programs in the fields of Distributed computing, Algorithm analysis, Machine Learning are continuously being carried out to tackle the ever increasing need of computation efficiency and speed. With this need in mind my future goal is to pursue a career in IT industry and aim towards computation on big data.</p><p>I am looking for co-op/full time opportunities as a software developer, and I believe that my experience, research and strong technical abilities would help me contribute immensely.</p>"
	},
	{
	    "heading":"CrowdSourced Interactive Reinforcement Learning",
	    "content":"<p>Learning from demonstration is a growing area of artificial intelligence research that explores techniques for programming autonomous agents (robots) by demonstrating the desired behavior or task. In demonstration-based approaches, a teacher, typically a human, shows the agent how to perform the task. The agent records the demonstrations as sequences of state- action pairs, from which it then learns a policy that reproduces the observed behavior.</p><p>Confidence Based Autonomy: A mapping approximation technique based on a classification algorithm. The human teacher (oracle) interacts with the robot by selecting the next action or correcting a past action choice through an on-screen interface. Confidence Based Autonomy is an active learning method that is based on asking for help from a human teacher when needed.</p><p>In most cases making a query to human asking for a classification task is costly in terms of time. My approach towards Confidence Based Autonomy is to use Reinforcement Learning to learn a policy that makes optimal human queries depending on the state of the supervised classifier.</p>"
	},
	{
	    "heading":"Annotating Large Scale Image Dataset",
	    "content":"<p>There are millions of images which are not labeled on the internet. Annotating images is important because images over internet are retrieved by keyword searches. If there are images which are not annotated, then those images are never retrieved in the search. So we are devoid of those annotated images. Applications are Detecting events, e.g. for visual surveillance of traffic lights, cars which have jumped the signal, finding missing person. Controlling processes, e.g. an industrial robot to inspect sites â€“ daily work . Navigation, e.g. using an autonomous vehicle.</p>"
	},
	{
	    "heading":"Predicting Bad Edits to Wikipedia Pages",
	    "content":"<p>According to the PAN 2010 Wikipedia Vandalism Detection training corpus , about 7% of all revisions were vandalized. This is a significant problem for Wikipedia, because the readers can never be sure of the quality of available information, unless they verify it from other sources. The problem is to identify whether a particular edit made to a wikipedia page is legitmiate and not an attempt to compromise the integrity of the page.</p><p>A wiki article from its birth undergoes a series of revision edits and is called as article history. A single revision is a state of the article at a given time in its history and is composed of the textual content, markup and metadata describing the transition from the previous history. A revision metadata contains the user who performed the edit, a comment explaining why the edit was made and describing the changes made to the article. A revision edit can be considered as a tuple containing the previous edit, the new edit and its corresponding metadata. The goal of the classifier is to output whether a particular edit made is good (no vandalism) or bad(vandalism).</p><p>The proposed method is to preprocess both (previous and new) revision edits pertaing to a single edit to remove the extra wiki markup and get pure text. Get the difference in the pure texts and compute metadata, text and language features which are then fed to the classifier.</p>"
	},
	{
	    "heading":"Encryption and Watermarking of Relational Data on Networking Sites",
	    "content":"<p>On-line social networking has become a very popular now a days. The paper studies the copyright issue of on-line social networking data in relational database. Techniques and concepts of mining for social network is discussed which gives rise to the need of watermarking its data. Proving ownership rights on such data is a crucial issue in social network which to some extent contribute to privacy preserving issue also. Watermark key is generated on vowel and consonant count and accordingly the profile image is scaled.</p>"
	}

    ]
}
